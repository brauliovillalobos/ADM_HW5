{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2cb346-2649-4deb-8403-ed0da19a9093",
   "metadata": {},
   "source": [
    "# Importing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a139a3-5e6c-4805-8039-56784db23d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b193d9bb-f62c-4e49-8eb6-5d91deabeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('interactions.pickle', 'rb') as handle:\n",
    "    my_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b041c9-7c45-4ce1-b926-3b4e5f254871",
   "metadata": {},
   "source": [
    "# Functionality 3 - Shortest Ordered Route\n",
    "\n",
    "It takes in input:\n",
    "\n",
    "* An interval of time\n",
    "* A sequence of users p = [p_2, ..., p_n-1]\n",
    "* Initial user p_1 and an end user p_n\n",
    "\n",
    "Implement an algorithm that returns the shortest walk that goes from user p_j to p_n, and that visits in order the nodes in p. The choice of p_j and p_n can be done randomly (or if it improves the performance of the algorithm you can also define it in any other way)\n",
    "\n",
    "Consider that:\n",
    "\n",
    "* The algorithm needs to handle the case that the graph is not connected, thus not all the nodes in p are reachable from p_1. In such scenario, it is enough to let the program give in output the string \"Not possible\".\n",
    "* That the graph is weighted\n",
    "* Since we are dealing with walks, you can pass more than once on the same node p_i, but you have to preserve order. E.g.: if you pass through p_2 and you are going to p_3, you can pass through p_10, but once you will be in p_9, you will have to go back to p_10 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5cffb-c34c-486b-844e-a5266863700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_date_to_int(date):\n",
    "    '''\n",
    "    INPUT: (day,month,year)\n",
    "    OUTPUT: correspondent integer\n",
    "    '''\n",
    "    if date[1]==2:\n",
    "        integer=date[0]+date[1]*28+(date[2]-1970)*365\n",
    "    if date[1] in [4,6,9,11]:\n",
    "        integer=date[0]+date[1]*30+(date[2]-1970)*365\n",
    "    else:\n",
    "        integer=date[0]+date[1]*31+(date[2]-1970)*365\n",
    "    return(integer)\n",
    "\n",
    "\n",
    "def convert_interval(interval):\n",
    "    '''\n",
    "    INPUT= interval of time in format [(dd,mm,yyyy),(dd,mm,yyyy)] --> [start,end]\n",
    "    OUTPUT: interval of time in format [encoded_start,encoded_end] where encoded are integers values\n",
    "    '''\n",
    "    new_int=[]\n",
    "    for date in interval:\n",
    "        new_int.append(from_date_to_int(date))\n",
    "    \n",
    "    return( new_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f335020-8646-4bc3-93b0-e32bb0e48322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_f(array_to_flatten):\n",
    "    '''\n",
    "    Function to flatten a list\n",
    "    '''\n",
    "    return [item for sublist in array_to_flatten for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0046c97-5d2a-4efe-b0a7-a633ed6b6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_timestamps_f(initial_time,final_time,dict_to_filter):\n",
    "    '''\n",
    "    Function that filters a graph and leaves only those edges with a timestamp within the interval of initial_time and final_time,\n",
    "    defined by the user. Function currently creates a new dictionary but it can be modified so that it updates the existing dictionary.\n",
    "    '''\n",
    "    #Create new dictionary\n",
    "    filtered_dictionary = {}\n",
    "    for each_key in dict_to_filter: #For each key in the dictionary\n",
    "        to_test = np.array(dict_to_filter[each_key])[:,1] #Extract only the timestamps \n",
    "        indexes_to_filter = flatten_f(np.where(np.bitwise_and(to_test>initial_time,to_test<final_time))) #Get indexes of the timestamps that are within the desired time intervals\n",
    "        values_for_key = dict_to_filter[each_key] #Extracts all edges associated with a specific key\n",
    "        \n",
    "        #Redefine values of a particular key\n",
    "        filtered_dictionary.update({each_key: [values_for_key[i] for i in indexes_to_filter]}) #Keeps only those edges that have timestamps within desired time intervals.\n",
    "    return(filtered_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096260d8-c258-41d1-9e4e-1b0b83b2a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "def standardize_weights_f(dict_to_standardize):\n",
    "    '''\n",
    "    Function used to summarise all edges with different weights into 1 single edge in a directed graph. It converts a multigraph in a graph. \n",
    "    '''\n",
    "    #Create new dictionary\n",
    "    standard_weighs_dictionary = {}\n",
    "    for each_key in dict_to_standardize:\n",
    "        if len(dict_to_standardize[each_key]) != 0: #If after the filtering the key doesn't have any edges, ignore that key. \n",
    "            #For each key, count how many times each associated vertex appears, and assign that as weight between the key and outgoing vertex\n",
    "            standard_weighs_dictionary.update({each_key: list(collections.Counter(np.array(dict_to_standardize[each_key])[:,0]).items())})\n",
    "    \n",
    "    return(standard_weighs_dictionary) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1db936-06a6-4ce9-8bfb-72cb79e86033",
   "metadata": {},
   "source": [
    "# Dijkstra Implementation filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bd328f-a4f2-417d-8eec-fa8145dce986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra_f(graph_to_analyze, start_vertex):\n",
    "    '''\n",
    "    Function used to run Dijkstra algorithm \n",
    "    '''\n",
    "    #****************************************1) Collect all vertexes in the graph**********************************\n",
    "    #Collect all keys (vertexes) in the graph\n",
    "    #Problem: There are other vertexes that are not keys since the graph is directed and also disconnected. We should consider them too. \n",
    "    related_nodes = list()\n",
    "    for each_key in graph_to_analyze.keys():\n",
    "        related_nodes.append([i for i in np.array(graph_to_analyze[each_key])[:,0]])\n",
    "    \n",
    "    #Union of sets: keys of the graph and vertexes that are not keys of the graph but still exist\n",
    "    vertexes = set(graph_to_analyze.keys()).union(set(flatten_f(related_nodes)))\n",
    "    \n",
    "    #*************************************2) Track which vertexes are still unvisited******************************\n",
    "    unvisited_vertexes = vertexes \n",
    "    #***********************************3) Keep track of the smallest distances to each node***********************\n",
    "    #All vertexes are set to have an infinite distance at the beginning. Then they'll be updated\n",
    "    default_distance = float('inf')\n",
    "    smallest_dist_dict = {k: default_distance for k in vertexes}\n",
    "    #Set distance of the starting vertex as zero\n",
    "    smallest_dist_dict[start_vertex] = 0\n",
    "    \n",
    "    #*******4) Keep track of the parent with the smallest distance from which we reach each visited vertex*********\n",
    "    parent_vertex = {k: 'nd' for k in vertexes}\n",
    "    \n",
    "    #Now while we still have vertexes that haven't been visited yet... keep rolling\n",
    "    while(len(unvisited_vertexes)>0):\n",
    "        #Create another dictionary with weights only for the unvisited vertexes\n",
    "        #We use this to select the vertex with the smallest distance and then move to it... 9 to 7 in dict_test_2\n",
    "        dict_unvisited_dist = {each_unvisited_node: smallest_dist_dict[each_unvisited_node] for each_unvisited_node in unvisited_vertexes}\n",
    "        \n",
    "        #We select, from the dictionary of unvisited vertexes, the vertex with the smallest weight\n",
    "        selected_vertex = min(dict_unvisited_dist, key=dict_unvisited_dist.get)\n",
    "        #We remove the selected vertex from unvisited as it is already visited. \n",
    "        unvisited_vertexes.remove(selected_vertex)\n",
    "        \n",
    "        #Now we have to update the distances from the selected vertex to each vertex that is related to it. \n",
    "        if(selected_vertex in graph_to_analyze.keys()): #If there are edges that go out from the selected vertex (aka is a key in graph) update distances of outgoing nodes\n",
    "            for each_related_vertex, dist_related_vertex in graph_to_analyze[selected_vertex]:\n",
    "                #If the distance from the selected vertex plus the dist to the related vertex is smaller than the already reported dist of relat vertex...update!\n",
    "                combined_dist = smallest_dist_dict[selected_vertex] + (1/dist_related_vertex) #Must be 1/dist_related_vertex since a bigger weight means more interactions. Dijkstra only on dist_related_vertex would find the least important relationships.\n",
    "                if(combined_dist < smallest_dist_dict[each_related_vertex]):\n",
    "                    #Update the just discovered shortest distance to the related vertex of the selected vertex\n",
    "                    smallest_dist_dict[each_related_vertex] = combined_dist\n",
    "                    #Keep track of who is the selected vertex that lead to the related_vertex with the shortest dist (aka as the parent)\n",
    "                    parent_vertex[each_related_vertex] = selected_vertex\n",
    "            #print(len(unvisited_vertexes))\n",
    "    \n",
    "    return smallest_dist_dict, parent_vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3555c-0cc0-4e12-aefc-d98cdde321e8",
   "metadata": {},
   "source": [
    "# Function to rebuild the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38ac3548-15b6-4623-8e78-c12ddae501e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_path_f(graph_to_analyze_inp,starting_vertex_inp,ending_vertex_inp):\n",
    "    '''\n",
    "    Runs Dijkstra from the starting vertex. Gets dict of min distance from starting_vertex to each vertex that can be reached from it\n",
    "    and gets dict of the parent vertex that lead to each vertex that can be reached from starting vertex. Then reconstructs the path.\n",
    "    '''\n",
    "    min_dist_dict, parent_dict = dijkstra_f(graph_to_analyze_inp,starting_vertex_inp) \n",
    "    \n",
    "    #List to reconstruct the path that lead to each vertex\n",
    "    path_to_goal = list()\n",
    "    #path_to_goal.append(ending_vertex)\n",
    "    #Define the goal vertex from which we will start constructing the path that lead to it from the starting_vertex\n",
    "    goal = starting_vertex_inp\n",
    "    \n",
    "    #While we haven't reached our goal vertex, keep rolling...unless it's impossible to construct a path between starting and ending vertex\n",
    "    #stopping_clause = False\n",
    "    while ending_vertex_inp != goal:\n",
    "        #If there's no parent vertex... it was not possible to reach ending_vertex from starting_vertex, so stop searching\n",
    "        if (ending_vertex_inp not in parent_dict.keys()) or (parent_dict[ending_vertex_inp] == 'nd'):\n",
    "            path_to_goal.clear()\n",
    "            return(print(\"Impossible to reach vertex\",ending_vertex_inp,\"from vertex\",goal,\"!\"))\n",
    "            #stopping_clause = True\n",
    "            break #Stop searching\n",
    "        else:\n",
    "            #print(parent_dict[ending_vertex]) #Debug\n",
    "            #Add the parent of the list to reconstruct the path that lead from starting_vertex to ending_vertex\n",
    "            path_to_goal.append(parent_dict[ending_vertex_inp])\n",
    "            #Redefine parent vertex for next iteration and continue searching backwards\n",
    "            ending_vertex_inp = parent_dict[ending_vertex_inp]\n",
    "    return(path_to_goal[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbb8aa-a6df-4cd2-b321-beea9cd73c7a",
   "metadata": {},
   "source": [
    "# Functionality 3\n",
    "Give a list and return the shortest walk between the starting_vertex and ending_vertex that visits in order the vertex in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "823a4a7f-8c74-4ace-9705-da7bd2859179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality_3(graph_to_analyze_inp, interval_time, p1, pn, p): #Where interval of time has to have a default\n",
    "    '''\n",
    "    Function that takes a graph, an interval of time and 1) A starting vertex 2) An ending (or goal) vertex 3) And a list of vertexes.\n",
    "    The goal is to find the shortest route between the starting vertex and the ending vertex, that passes through the list of vertexes in order.\n",
    "    For this the function breaks the list in couples of subsequent vertexes and finds the shortest route between them\n",
    "    Collects the shortest paths in a list and finds, at the end, the shortest route between starting and ending vertex. \n",
    "    '''\n",
    "    #First filter the graph by time interval\n",
    "    converted_interval=convert_interval(interval_time) #Transforming inputs of date intervals into integers\n",
    "    #Filter the graph by the timestamps (converted to integers) given by the user\n",
    "    filtered_dict = filter_by_timestamps_f(converted_interval[0],converted_interval[1],graph_to_analyze_inp)\n",
    "    #Second standardize the filtered graph to sum up the weights of all the edges with the same direction between each pair of vertexes\n",
    "    graph_to_analyze = standardize_weights_f(filtered_dict)\n",
    "\n",
    "    if isinstance(p, list):\n",
    "        p.insert(0,p1) #Set the parameter p1 as the first element of the list p.\n",
    "        p.insert(len(p),pn) #Set the parameter pn as the last element of the list p. \n",
    "        \n",
    "        shortest_route = list() #Define a list to collect the shortest route between a couple of vertexes\n",
    "        \n",
    "        for i in range(0,len(p)-1): #Goes through the list given by the user taking couples of vertexes\n",
    "            \n",
    "            starting_vertex = p[i] #Take the first vertex of the couple\n",
    "            ending_vertex = p[i+1] #Take the second vertex of the couple\n",
    "            \n",
    "            #Explore the shortest path between starting and ending vertex\n",
    "            path = reconstruct_path_f(graph_to_analyze,starting_vertex,ending_vertex) \n",
    "            #Check if the returned type is None\n",
    "            if path is None:\n",
    "                break\n",
    "            #Save the path found between the 2 vertexes\n",
    "            shortest_route.extend(path) \n",
    "            \n",
    "            #If is the last iteration, and all the paths have been found, just append the goal vertex to the list.\n",
    "            if i == (len(p)-2): \n",
    "                shortest_route.append(pn) #This can be removed. \n",
    "    else:\n",
    "        print(\"Input p is not a list. Please insert a object of type list.\")\n",
    "    \n",
    "    return shortest_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96b9db19-46ee-4b63-82d2-288d45ea91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_f3 = functionality_3(my_dict,[(4,1,2011),(6,1,2011)],267,589854,[476,1053,1968])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa11155c-4c8e-447f-b921-0e703f584e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[267,\n",
       " 48465,\n",
       " 8992,\n",
       " 289466,\n",
       " 84325,\n",
       " 68105,\n",
       " 155077,\n",
       " 296568,\n",
       " 419970,\n",
       " 449907,\n",
       " 476,\n",
       " 386579,\n",
       " 187606,\n",
       " 524436,\n",
       " 481061,\n",
       " 456,\n",
       " 585737,\n",
       " 415784,\n",
       " 317283,\n",
       " 165520,\n",
       " 505259,\n",
       " 1053,\n",
       " 501518,\n",
       " 501146,\n",
       " 556363,\n",
       " 14955,\n",
       " 212443,\n",
       " 429982,\n",
       " 511601,\n",
       " 13005,\n",
       " 1968,\n",
       " 19563,\n",
       " 252047,\n",
       " 511601,\n",
       " 429982,\n",
       " 573261,\n",
       " 589854]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_f3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
