{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2cb346-2649-4deb-8403-ed0da19a9093",
   "metadata": {},
   "source": [
    "# Importing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b193d9bb-f62c-4e49-8eb6-5d91deabeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('interactions.pickle', 'rb') as handle:\n",
    "    my_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b041c9-7c45-4ce1-b926-3b4e5f254871",
   "metadata": {},
   "source": [
    "# Functionality 3 - Shortest Ordered Route\n",
    "\n",
    "It takes in input:\n",
    "\n",
    "* An interval of time\n",
    "* A sequence of users p = [p_2, ..., p_n-1]\n",
    "* Initial user p_1 and an end user p_n\n",
    "\n",
    "Implement an algorithm that returns the shortest walk that goes from user p_j to p_n, and that visits in order the nodes in p. The choice of p_j and p_n can be done randomly (or if it improves the performance of the algorithm you can also define it in any other way)\n",
    "\n",
    "Consider that:\n",
    "\n",
    "* The algorithm needs to handle the case that the graph is not connected, thus not all the nodes in p are reachable from p_1. In such scenario, it is enough to let the program give in output the string \"Not possible\".\n",
    "* That the graph is weighted\n",
    "* Since we are dealing with walks, you can pass more than once on the same node p_i, but you have to preserve order. E.g.: if you pass through p_2 and you are going to p_3, you can pass through p_10, but once you will be in p_9, you will have to go back to p_10 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f335020-8646-4bc3-93b0-e32bb0e48322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_f(array_to_flatten):\n",
    "    return [item for sublist in array_to_flatten for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0046c97-5d2a-4efe-b0a7-a633ed6b6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_timestamps_f(initial_time,final_time,dict_to_filter):\n",
    "    '''\n",
    "    Function that filters a graph and leaves only those edges with a timestamp within the interval of initial_time and final_time,\n",
    "    defined by the user. Function currently creates a new dictionary but it can be modified so that it updates the existing dictionary.\n",
    "    '''\n",
    "    #Create new dictionary\n",
    "    filtered_dictionary = {}\n",
    "    for each_key in dict_to_filter: #For each key in the dictionary\n",
    "        to_test = np.array(dict_to_filter[each_key])[:,1] #Extract only the timestamps \n",
    "        indexes_to_filter = flatten_f(np.where(np.bitwise_and(to_test>initial_time,to_test<final_time))) #Get indexes of the timestamps that are within the desired time intervals\n",
    "        values_for_key = dict_to_filter[each_key] #Extracts all edges associated with a specific key\n",
    "        \n",
    "        #Redefine values of a particular key\n",
    "        filtered_dictionary.update({each_key: [values_for_key[i] for i in indexes_to_filter]}) #Keeps only those edges that have timestamps within desired time intervals.\n",
    "    return(filtered_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362a3200-7a8a-4f3d-ad78-3afa4daa0bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.87537479400635\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "filtered_dict = filter_by_timestamps_f(15000,15020,my_dict)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "096260d8-c258-41d1-9e4e-1b0b83b2a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "def standardize_weights(dict_to_standardize):\n",
    "    #Create new dictionary\n",
    "    standard_weighs_dictionary = {}\n",
    "    for each_key in dict_to_standardize:\n",
    "        standard_weighs_dictionary.update({each_key: list(collections.Counter(np.array(dict_to_standardize[each_key])[:,0]).items())})\n",
    "    \n",
    "    return(standard_weighs_dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1ce4e7b-cde4-41f5-9b53-8d40f748099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539.1119320392609\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "graph_with_merged_weights = standardize_weights(my_dict)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b58cb6d-1646-49ba-a3d0-421b27680ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_2 = {\n",
    "9: [[8, 1217567877, 10]],\n",
    "13: [[1, 1217606247, 10], [23, 1217618560, 10], [11, 1217618799, 10]],\n",
    "17: [[1, 1217617639, 10], [1, 1217618239, 10]],\n",
    "48: [[2, 1217618182, 10]],\n",
    "19: [[9, 1217618357, 10]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d251b0c-bb91-47db-a4ce-4cab1bb2fdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: [(8, 1)],\n",
       " 13: [(1, 1), (23, 1), (11, 1)],\n",
       " 17: [(1, 2)],\n",
       " 48: [(2, 1)],\n",
       " 19: [(9, 1)]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test_2 = standardize_weights(dict_test_2)\n",
    "dict_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1db936-06a6-4ce9-8bfb-72cb79e86033",
   "metadata": {},
   "source": [
    "# Dijkstra Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30bd328f-a4f2-417d-8eec-fa8145dce986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra(graph_to_analyze, start_vertex):\n",
    "    #****************************************1) Collect all vertexes in the graph**********************************\n",
    "    #Collect all keys (vertexes) in the graph\n",
    "    #Problem: There are other vertexes that are not keys since the graph is directed and also disconnected. We should consider them too. \n",
    "    related_nodes = list()\n",
    "    for each_key in graph_to_analyze.keys():\n",
    "        related_nodes.append([i for i in np.array(graph_to_analyze[each_key])[:,0]])\n",
    "    \n",
    "    #Union of sets: keys of the graph and vertexes that are not keys of the graph but still exist\n",
    "    vertexes = set(graph_to_analyze.keys()).union(set(flatten_f(related_nodes)))\n",
    "    \n",
    "    #*************************************2) Track which vertexes are still unvisited******************************\n",
    "    unvisited_vertexes = vertexes \n",
    "    #***********************************3) Keep track of the smallest distances to each node***********************\n",
    "    #All vertexes are set to have an infinite distance at the beginning. Then they'll be updated\n",
    "    default_distance = float('inf')\n",
    "    smallest_dist_dict = {k: default_distance for k in vertexes}\n",
    "    #Set distance of the starting vertex as zero\n",
    "    smallest_dist_dict[start_vertex] = 0\n",
    "    \n",
    "    #*******4) Keep track of the parent with the smallest distance from which we reach each visited vertex*********\n",
    "    parent_vertex = {k: 'nd' for k in vertexes}\n",
    "    \n",
    "    #Now while we still have vertexes that haven't been visited yet... keep rolling\n",
    "    while(len(unvisited_vertexes)>0):\n",
    "        #Create another dictionary with weights only for the unvisited vertexes\n",
    "        #We use this to select the vertex with the smallest distance and then move to it... 9 to 7 in dict_test_2\n",
    "        dict_unvisited_dist = {each_unvisited_node: smallest_dist_dict[each_unvisited_node] for each_unvisited_node in unvisited_vertexes}\n",
    "        \n",
    "        #We select, from the dictionary of unvisited vertexes, the vertex with the smallest weight\n",
    "        selected_vertex = min(dict_unvisited_dist, key=dict_unvisited_dist.get)\n",
    "        #We remove the selected vertex from unvisited as it is already visited. \n",
    "        unvisited_vertexes.remove(selected_vertex)\n",
    "        \n",
    "        #Now we have to update the distances from the selected vertex to each vertex that is related to it. \n",
    "        if(selected_vertex in graph_to_analyze.keys()): #If there are edges that go out from the selected vertex (aka is a key in graph) update distances of outgoing nodes\n",
    "            for each_related_vertex, dist_related_vertex in graph_to_analyze[selected_vertex]:\n",
    "                #If the distance from the selected vertex plus the dist to the related vertex is smaller than the already reported dist of relat vertex...update!\n",
    "                combined_dist = smallest_dist_dict[selected_vertex] + (1/dist_related_vertex)\n",
    "                if(combined_dist < smallest_dist_dict[each_related_vertex]):\n",
    "                    #Update the just discovered shortest distance to the related vertex of the selected vertex\n",
    "                    smallest_dist_dict[each_related_vertex] = combined_dist\n",
    "                    #Keep track of who is the selected vertex that lead to the related_vertex with the shortest dist (aka as the parent)\n",
    "                    parent_vertex[each_related_vertex] = selected_vertex\n",
    "            print(len(unvisited_vertexes))\n",
    "    \n",
    "    return smallest_dist_dict, parent_vertex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
