{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2cb346-2649-4deb-8403-ed0da19a9093",
   "metadata": {},
   "source": [
    "# Importing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a139a3-5e6c-4805-8039-56784db23d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b193d9bb-f62c-4e49-8eb6-5d91deabeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('interactions.pickle', 'rb') as handle:\n",
    "    my_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b041c9-7c45-4ce1-b926-3b4e5f254871",
   "metadata": {},
   "source": [
    "# Functionality 3 - Shortest Ordered Route\n",
    "\n",
    "It takes in input:\n",
    "\n",
    "* An interval of time\n",
    "* A sequence of users p = [p_2, ..., p_n-1]\n",
    "* Initial user p_1 and an end user p_n\n",
    "\n",
    "Implement an algorithm that returns the shortest walk that goes from user p_j to p_n, and that visits in order the nodes in p. The choice of p_j and p_n can be done randomly (or if it improves the performance of the algorithm you can also define it in any other way)\n",
    "\n",
    "Consider that:\n",
    "\n",
    "* The algorithm needs to handle the case that the graph is not connected, thus not all the nodes in p are reachable from p_1. In such scenario, it is enough to let the program give in output the string \"Not possible\".\n",
    "* That the graph is weighted\n",
    "* Since we are dealing with walks, you can pass more than once on the same node p_i, but you have to preserve order. E.g.: if you pass through p_2 and you are going to p_3, you can pass through p_10, but once you will be in p_9, you will have to go back to p_10 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f335020-8646-4bc3-93b0-e32bb0e48322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_f(array_to_flatten):\n",
    "    return [item for sublist in array_to_flatten for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0046c97-5d2a-4efe-b0a7-a633ed6b6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_timestamps_f(initial_time,final_time,dict_to_filter):\n",
    "    '''\n",
    "    Function that filters a graph and leaves only those edges with a timestamp within the interval of initial_time and final_time,\n",
    "    defined by the user. Function currently creates a new dictionary but it can be modified so that it updates the existing dictionary.\n",
    "    '''\n",
    "    #Create new dictionary\n",
    "    filtered_dictionary = {}\n",
    "    for each_key in dict_to_filter: #For each key in the dictionary\n",
    "        to_test = np.array(dict_to_filter[each_key])[:,1] #Extract only the timestamps \n",
    "        indexes_to_filter = flatten_f(np.where(np.bitwise_and(to_test>initial_time,to_test<final_time))) #Get indexes of the timestamps that are within the desired time intervals\n",
    "        values_for_key = dict_to_filter[each_key] #Extracts all edges associated with a specific key\n",
    "        \n",
    "        #Redefine values of a particular key\n",
    "        filtered_dictionary.update({each_key: [values_for_key[i] for i in indexes_to_filter]}) #Keeps only those edges that have timestamps within desired time intervals.\n",
    "    return(filtered_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362a3200-7a8a-4f3d-ad78-3afa4daa0bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.3041479587555\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "filtered_dict = filter_by_timestamps_f(15000,15020,my_dict)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096260d8-c258-41d1-9e4e-1b0b83b2a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "def standardize_weights_f(dict_to_standardize):\n",
    "    #Create new dictionary\n",
    "    standard_weighs_dictionary = {}\n",
    "    for each_key in dict_to_standardize:\n",
    "        standard_weighs_dictionary.update({each_key: list(collections.Counter(np.array(dict_to_standardize[each_key])[:,0]).items())})\n",
    "    \n",
    "    return(standard_weighs_dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ce4e7b-cde4-41f5-9b53-8d40f748099f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6a81f9293576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgraph_with_merged_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cc5ade17449c>\u001b[0m in \u001b[0;36mstandardize_weights\u001b[0;34m(dict_to_standardize)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstandard_weighs_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meach_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_to_standardize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mstandard_weighs_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0meach_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_to_standardize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstandard_weighs_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "graph_with_merged_weights = standardize_weights_f(filtered_dict)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1db936-06a6-4ce9-8bfb-72cb79e86033",
   "metadata": {},
   "source": [
    "# Dijkstra Implementation filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bd328f-a4f2-417d-8eec-fa8145dce986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra_f(graph_to_analyze, start_vertex):\n",
    "    #****************************************1) Collect all vertexes in the graph**********************************\n",
    "    #Collect all keys (vertexes) in the graph\n",
    "    #Problem: There are other vertexes that are not keys since the graph is directed and also disconnected. We should consider them too. \n",
    "    related_nodes = list()\n",
    "    for each_key in graph_to_analyze.keys():\n",
    "        related_nodes.append([i for i in np.array(graph_to_analyze[each_key])[:,0]])\n",
    "    \n",
    "    #Union of sets: keys of the graph and vertexes that are not keys of the graph but still exist\n",
    "    vertexes = set(graph_to_analyze.keys()).union(set(flatten_f(related_nodes)))\n",
    "    \n",
    "    #*************************************2) Track which vertexes are still unvisited******************************\n",
    "    unvisited_vertexes = vertexes \n",
    "    #***********************************3) Keep track of the smallest distances to each node***********************\n",
    "    #All vertexes are set to have an infinite distance at the beginning. Then they'll be updated\n",
    "    default_distance = float('inf')\n",
    "    smallest_dist_dict = {k: default_distance for k in vertexes}\n",
    "    #Set distance of the starting vertex as zero\n",
    "    smallest_dist_dict[start_vertex] = 0\n",
    "    \n",
    "    #*******4) Keep track of the parent with the smallest distance from which we reach each visited vertex*********\n",
    "    parent_vertex = {k: 'nd' for k in vertexes}\n",
    "    \n",
    "    #Now while we still have vertexes that haven't been visited yet... keep rolling\n",
    "    while(len(unvisited_vertexes)>0):\n",
    "        #Create another dictionary with weights only for the unvisited vertexes\n",
    "        #We use this to select the vertex with the smallest distance and then move to it... 9 to 7 in dict_test_2\n",
    "        dict_unvisited_dist = {each_unvisited_node: smallest_dist_dict[each_unvisited_node] for each_unvisited_node in unvisited_vertexes}\n",
    "        \n",
    "        #We select, from the dictionary of unvisited vertexes, the vertex with the smallest weight\n",
    "        selected_vertex = min(dict_unvisited_dist, key=dict_unvisited_dist.get)\n",
    "        #We remove the selected vertex from unvisited as it is already visited. \n",
    "        unvisited_vertexes.remove(selected_vertex)\n",
    "        \n",
    "        #Now we have to update the distances from the selected vertex to each vertex that is related to it. \n",
    "        if(selected_vertex in graph_to_analyze.keys()): #If there are edges that go out from the selected vertex (aka is a key in graph) update distances of outgoing nodes\n",
    "            for each_related_vertex, dist_related_vertex in graph_to_analyze[selected_vertex]:\n",
    "                #If the distance from the selected vertex plus the dist to the related vertex is smaller than the already reported dist of relat vertex...update!\n",
    "                combined_dist = smallest_dist_dict[selected_vertex] + (1/dist_related_vertex)\n",
    "                if(combined_dist < smallest_dist_dict[each_related_vertex]):\n",
    "                    #Update the just discovered shortest distance to the related vertex of the selected vertex\n",
    "                    smallest_dist_dict[each_related_vertex] = combined_dist\n",
    "                    #Keep track of who is the selected vertex that lead to the related_vertex with the shortest dist (aka as the parent)\n",
    "                    parent_vertex[each_related_vertex] = selected_vertex\n",
    "            #print(len(unvisited_vertexes))\n",
    "    \n",
    "    return smallest_dist_dict, parent_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f997ee72-33e3-4cb4-b9e5-08fd16902222",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_2 = {\n",
    "9: [[8, 1217567877, 10],[13, 1217567877, 10],[13, 1217567877, 10],[17, 1217567877, 10],[17, 1217567877, 10],[17, 1217567877, 10]],\n",
    "13: [[1, 1217606247, 10], [23, 1217618560, 10], [11, 1217618799, 10]],\n",
    "17: [[1, 1217617639, 10], [1, 1217618239, 10]],\n",
    "48: [[2, 1217618182, 10]],\n",
    "19: [[9, 1217618357, 10]],\n",
    "23: [[19, 1217618357, 10],[19, 1217618357, 10],[19, 1217618357, 10],[48, 1217618357, 10]],    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79662a4b-f1c3-4def-b2dc-67740702d577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b81cd7d-a345-4343-92f7-a5d7f62d0ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: [(8, 1), (13, 2), (17, 3)],\n",
       " 13: [(1, 1), (23, 1), (11, 1)],\n",
       " 17: [(1, 2)],\n",
       " 48: [(2, 1)],\n",
       " 19: [(9, 1)],\n",
       " 23: [(19, 3)]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test_2 = standardize_weights_f(dict_test_2)\n",
    "dict_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a29bf02a-3cff-43b7-bec8-faddeee75e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_2 = {\n",
    "9: [[8,1],[13,2],[17,3]],\n",
    "19: [[9,1]],\n",
    "48: [[2,1]],\n",
    "2: [[88,3]],\n",
    "17: [[1,2],[99,4]],\n",
    "13: [[11,1], [1,1], [23,3]],\n",
    "23: [[48,7], [19,3]],\n",
    "99: [[101,3],[88,10],[77,1]],\n",
    "101: [[77, 3]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eed0af8b-cdb6-49d0-aab3-e35c79cd99d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 0.8333333333333333,\n",
       "  2: inf,\n",
       "  8: 1.0,\n",
       "  9: 0,\n",
       "  11: 1.5,\n",
       "  13: 0.5,\n",
       "  48: inf,\n",
       "  17: 0.3333333333333333,\n",
       "  19: 1.8333333333333333,\n",
       "  23: 1.5},\n",
       " {1: 17,\n",
       "  2: 'nd',\n",
       "  8: 9,\n",
       "  9: 'nd',\n",
       "  11: 13,\n",
       "  13: 9,\n",
       "  48: 'nd',\n",
       "  17: 9,\n",
       "  19: 23,\n",
       "  23: 13})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dijkstra_f(dict_test_2,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3555c-0cc0-4e12-aefc-d98cdde321e8",
   "metadata": {},
   "source": [
    "# Function to rebuild the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38ac3548-15b6-4623-8e78-c12ddae501e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_path_f(graph_to_analyze,starting_vertex,ending_vertex):\n",
    "    #Run Dijkstra from the starting_vertex. Gets dict of min distance from starting_vertex to each vertex that can be reached from it\n",
    "    #and gets dict of the parent vertex that lead to each vertex that can be reached from the starting_vertex\n",
    "    min_dist_dict, parent_dict = dijkstra_f(graph_to_analyze,starting_vertex) \n",
    "    \n",
    "    #List to reconstruct the path that lead to each vertex\n",
    "    path_to_goal = list()\n",
    "    #path_to_goal.append(ending_vertex)\n",
    "    #Define the goal vertex from which we will start constructing the path that lead to it from the starting_vertex\n",
    "    goal = starting_vertex\n",
    "    \n",
    "    #While we haven't reached our goal vertex, keep rolling...unless it's impossible to construct a path between starting and ending vertex\n",
    "    while(ending_vertex != goal):\n",
    "        #If there's no parent vertex... it was not possible to reach ending_vertex from starting_vertex, so stop searching\n",
    "        if parent_dict[ending_vertex] == 'nd':\n",
    "            print(\"Impossible to reach vertex\",ending_vertex,\"from vertex\",goal,\"!\")\n",
    "            path_to_goal.clear()\n",
    "            break #Stop searching\n",
    "        else:\n",
    "            #print(parent_dict[ending_vertex]) #Debug\n",
    "            #Add the parent of the list to reconstruct the path that lead from starting_vertex to ending_vertex\n",
    "            path_to_goal.append(parent_dict[ending_vertex])\n",
    "            #Redefine parent vertex for next iteration and continue searching backwards\n",
    "            ending_vertex = parent_dict[ending_vertex]\n",
    "    return(path_to_goal[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a01fee36-17e3-47af-a7b3-a84c140a7682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 7 does not exist in the graph.\n"
     ]
    }
   ],
   "source": [
    "zzz = reconstruct_path_f(dict_test_2,7,88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "25b3e567-f31c-4a4c-99ea-75057c1c16c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 9, 17, 99, 88, 100]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c743ab2d-c010-428c-86d4-d23510104875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([9, 19, 48, 2, 17, 13, 23, 99, 101])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test_2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbb8aa-a6df-4cd2-b321-beea9cd73c7a",
   "metadata": {},
   "source": [
    "# Functionality 3\n",
    "Give a list and return the shortest walk between the starting_vertex and ending_vertex that visits in order the vertex in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1615e40-1b6d-43f3-9889-e74aad57a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_2 = {\n",
    "9: [[8,1],[13,2],[17,3]],\n",
    "19: [[9,1],[23,3]],\n",
    "48: [[2,1]],\n",
    "2: [[88,3]],\n",
    "17: [[1,2],[99,4]],\n",
    "13: [[11,1], [1,1], [23,3]],\n",
    "23: [[19,3],[48,7]],\n",
    "99: [[101,3],[88,10],[77,1]],\n",
    "101: [[77, 3]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773d350-531d-4d47-be05-6c50c1a4b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receives a list of vertexes\n",
    "#Breaks the list in couples of subsequent vertexes\n",
    "#Finds shortest route between this couple of vertexes\n",
    "#Collects the shortest route in a list\n",
    "#At the end we find the shortest route that connnects first vertex with final vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823a4a7f-8c74-4ace-9705-da7bd2859179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality_3(graph_to_analyze, interval_time, p1, pn, p): #Where interval of time has to have a default\n",
    "    if isinstance(p, list):\n",
    "        p.insert(0,p1) #Set the parameter p1 as the first element of the list p.\n",
    "        p.insert(len(p),pn) #Set the parameter pn as the last element of the list p. \n",
    "        \n",
    "        shortest_route = list() #Define a list to collect the shortest route between a couple of vertexes\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Input p is not a list. Please insert a object of type list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "002cedd6-7367-4fe1-b9ba-c8c0220dd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 19\n",
    "p = [23,9,48]\n",
    "pn = 88\n",
    "\n",
    "p.insert(0,p1)\n",
    "p.insert(len(p),pn)\n",
    "\n",
    "shortest_route = list()\n",
    "for i in range(0,len(p)-1):\n",
    "    starting_vertex = p[i]\n",
    "    ending_vertex = p[i+1]\n",
    "    #print(starting_vertex,ending_vertex)\n",
    "    path = reconstruct_path_f(dict_test_2,starting_vertex,ending_vertex)\n",
    "    \n",
    "    shortest_route.extend(path)\n",
    "\n",
    "    if i == (len(p)-2):\n",
    "        shortest_route.append(pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd587583-0981-4cda-91c1-d53bfec3bc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 23, 19, 9, 13, 23, 48, 2, 88]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a20d6877-1bce-4038-a588-7678fa7c1d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 2.1666666666666665,\n",
       "  2: inf,\n",
       "  8: 2.333333333333333,\n",
       "  9: 1.3333333333333333,\n",
       "  11: 2.833333333333333,\n",
       "  13: 1.8333333333333333,\n",
       "  77: 2.5833333333333335,\n",
       "  17: 1.6666666666666665,\n",
       "  19: 0.3333333333333333,\n",
       "  23: 0,\n",
       "  88: 2.0166666666666666,\n",
       "  99: 1.9166666666666665,\n",
       "  101: 2.25,\n",
       "  48: inf},\n",
       " {1: 17,\n",
       "  2: 'nd',\n",
       "  8: 9,\n",
       "  9: 19,\n",
       "  11: 13,\n",
       "  13: 9,\n",
       "  77: 101,\n",
       "  17: 9,\n",
       "  19: 23,\n",
       "  23: 'nd',\n",
       "  88: 99,\n",
       "  99: 17,\n",
       "  101: 99,\n",
       "  48: 'nd'})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dijkstra_f(dict_test_2,23)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
