{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9837919f-712f-4238-bac4-060614a6ef9b",
   "metadata": {},
   "source": [
    "# Homework 5 - Algorithmic Methods of Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2cb346-2649-4deb-8403-ed0da19a9093",
   "metadata": {},
   "source": [
    "#### Importing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d956298-05ed-48be-b5db-39df82c3e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc5945-8946-45f8-826d-f53e6093c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('interactions.pickle', 'rb') as handle:\n",
    "    my_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790293bf-9e3a-4096-ac0c-903395a9bc81",
   "metadata": {},
   "source": [
    "# Functionality 1 - Get the overall features of the graph\n",
    "\n",
    "It takes in input:\n",
    "\n",
    "* One of the 3 graphs\n",
    "\n",
    "The output should return:\n",
    "\n",
    "* Whether the graph is directed or not\n",
    "* Number of users\n",
    "* Number of answers/comments\n",
    "* Average number of links per user\n",
    "* Density degree of the graph\n",
    "* Whether the graph is sparse or dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0fb0a-e41a-4e53-b5be-d09f54599582",
   "metadata": {},
   "source": [
    "#### 1.1 Graph is directed or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47659328-c779-49fe-be6b-420e9460418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directed_or_undirected_f(dict_to_search):\n",
    "    '''\n",
    "    If a vertex u has a edge that goes to vertex v, and v doesn't have a vertex that goes back to u, then the graph is directed. \n",
    "    We will prove this by checking the keys of our dictionary until we find the descripted situation. \n",
    "    '''\n",
    "    is_directed = True # Suppose graph is directed until proven the contrary\n",
    "    \n",
    "    for each_key in dict_to_search.keys(): #for each key of the dictionary\n",
    "        \n",
    "        target_nodes = set(np.array(dict_to_search[each_key])[:,0])\n",
    "        for each_adjacent_node in target_nodes:\n",
    "            if(each_adjacent_node not in dict_to_search.keys()): #If the adjacent node is not in keys, then there's not edge going back\n",
    "                is_directed = False\n",
    "                return(is_directed)\n",
    "            \n",
    "            adjacent_nodes = set(np.array(dict_to_search[each_adjacent_node])[:,0])\n",
    "            \n",
    "            if(each_key not in adjacent_nodes):\n",
    "                is_directed = False\n",
    "                return(is_directed)\n",
    "    return(is_directed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920bcb2-7006-40e1-af56-1164e1b7e99e",
   "metadata": {},
   "source": [
    "#### 1.2 Number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505dfe3-4da0-4a68-a651-375a7a776d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_users_f(dict_to_search):\n",
    "    \n",
    "    dict_keys = set(dict_to_search.keys())\n",
    "    total_users = dict_keys\n",
    "    \n",
    "    for each_key in dict_keys.copy():\n",
    "        target_nodes = set(np.array(dict_to_search[each_key])[:,0])\n",
    "        difference = target_nodes.difference(total_users)\n",
    "        total_users.update(difference)\n",
    "    \n",
    "    return(len(total_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017b33b-9174-4de1-b9db-c44ffe3ba755",
   "metadata": {},
   "source": [
    "#### 1.3 Number of answers/comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a831b84-2f6d-42ef-8d20-05831d6acd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "196a9105-7de9-44cd-8e8c-8546830f39bb",
   "metadata": {},
   "source": [
    "#### 1.4 Average number of links per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9162ba-154a-460f-89d4-3326beeb5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outgoing_edges_f(dict_to_search):\n",
    "    '''\n",
    "    Function computes the total number of edges that exit from all the keys of the dictionary\n",
    "    '''\n",
    "    num_outgoing_edges = 0\n",
    "    \n",
    "    for each_key in dict_to_search.keys(): #Takes each key of the dictionary\n",
    "        outgoing_edges = np.array(dict_to_search[each_key])[:,0] #Takes each target node for a particular source node\n",
    "        num_outgoing_edges += len(outgoing_edges) #Increases the total number of outgoing edges by the total target nodes for a particular source node\n",
    "    \n",
    "    return(num_outgoing_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583741b0-dc7f-4e1c-85e0-755119cf4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_num_links_f(num_of_users,num_of_edges):\n",
    "    '''\n",
    "    Function compues the average number of links per user by dividing the total number of edges of the dictionaty by the total number of users\n",
    "    '''\n",
    "    #num_outgoing_edges = outgoing_edges_f(dict_to_search)\n",
    "    \n",
    "    average_num_links = num_of_edges/num_of_users\n",
    "    \n",
    "    return(average_num_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9187ddc-83af-457f-bad5-dc54280bd716",
   "metadata": {},
   "source": [
    "#### 1.5 Density degree of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472472f-e85c-4938-b51d-cc7382ae5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_density_f(edges_num, vertexes_num):\n",
    "    return(edges_num/(vertexes_num*(vertexes_num-1))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf44976-b5e4-4d23-a0f7-f21b1db128f0",
   "metadata": {},
   "source": [
    "#### 1.6 Whether the graph is sparse or dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5efb1-2a16-4e9f-9db4-802d7ba01bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_or_dense_f(density_degree,threshold):\n",
    "    if density_degree >= threshold:\n",
    "        sparsity_result = \"Is dense with a threshold of \"+str(threshold)+\"!\"\n",
    "    else:\n",
    "        sparsity_result = \"Is sparse with a threshold of \"+str(threshold)+\"!\"\n",
    "    return sparsity_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511cc34-15d3-4d01-bbbb-781d3d178f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality_1(dict_to_search):\n",
    "    number_vertexes = number_of_users_f(dict_to_search)\n",
    "    number_edges = outgoing_edges_f(dict_to_search)\n",
    "    graph_density = graph_density_f(number_edges,number_vertexes)\n",
    "    directed_or_undirected = (\"The graph is undirected\") if directed_or_undirected_f(dict_to_search) else (\"The graph is directed\")\n",
    "\n",
    "    output_f1 = {'Info': ['Graph is directed or undirected?', 'Total number of users', 'Total number of answers/comments', \n",
    "                 'Average number of links per user','Graph Density Degree','Graph is sparse or dense?'],\n",
    "                 'Result': [directed_or_undirected,number_vertexes,'NA',avg_num_links_f(number_vertexes,number_edges),\n",
    "                           graph_density,sparse_or_dense_f(graph_density,0.1)]}\n",
    "    output_f1 = pd.DataFrame(output_f1)\n",
    "    \n",
    "    return output_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55d6a0-5e3d-4b6c-899e-fa8cfb50c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "functionality_1(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b041c9-7c45-4ce1-b926-3b4e5f254871",
   "metadata": {},
   "source": [
    "# Functionality 3 - Shortest Ordered Route\n",
    "\n",
    "It takes in input:\n",
    "\n",
    "* An interval of time\n",
    "* A sequence of users p = [p_2, ..., p_n-1]\n",
    "* Initial user p_1 and an end user p_n\n",
    "\n",
    "Implement an algorithm that returns the shortest walk that goes from user p_j to p_n, and that visits in order the nodes in p. The choice of p_j and p_n can be done randomly (or if it improves the performance of the algorithm you can also define it in any other way)\n",
    "\n",
    "Consider that:\n",
    "\n",
    "* The algorithm needs to handle the case that the graph is not connected, thus not all the nodes in p are reachable from p_1. In such scenario, it is enough to let the program give in output the string \"Not possible\".\n",
    "* That the graph is weighted\n",
    "* Since we are dealing with walks, you can pass more than once on the same node p_i, but you have to preserve order. E.g.: if you pass through p_2 and you are going to p_3, you can pass through p_10, but once you will be in p_9, you will have to go back to p_10 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0fa5cffb-c34c-486b-844e-a5266863700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_date_to_int(date):\n",
    "    '''\n",
    "    INPUT: (day,month,year)\n",
    "    OUTPUT: correspondent integer\n",
    "    '''\n",
    "    if date[1]==2:\n",
    "        integer=date[0]+date[1]*28+(date[2]-1970)*365\n",
    "    if date[1] in [4,6,9,11]:\n",
    "        integer=date[0]+date[1]*30+(date[2]-1970)*365\n",
    "    else:\n",
    "        integer=date[0]+date[1]*31+(date[2]-1970)*365\n",
    "    return(integer)\n",
    "\n",
    "\n",
    "def convert_interval(interval):\n",
    "    '''\n",
    "    INPUT= interval of time in format [(dd,mm,yyyy),(dd,mm,yyyy)] --> [start,end]\n",
    "    OUTPUT: interval of time in format [encoded_start,encoded_end] where encoded are integers values\n",
    "    '''\n",
    "    new_int=[]\n",
    "    for date in interval:\n",
    "        new_int.append(from_date_to_int(date))\n",
    "    \n",
    "    return( new_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1f335020-8646-4bc3-93b0-e32bb0e48322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_f(array_to_flatten):\n",
    "    '''\n",
    "    Function to flatten a list\n",
    "    '''\n",
    "    return [item for sublist in array_to_flatten for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0046c97-5d2a-4efe-b0a7-a633ed6b6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_timestamps_f(initial_time,final_time,dict_to_filter):\n",
    "    '''\n",
    "    Function that filters a graph and leaves only those edges with a timestamp within the interval of initial_time and final_time,\n",
    "    defined by the user. Function currently creates a new dictionary but it can be modified so that it updates the existing dictionary.\n",
    "    '''\n",
    "    #Create new dictionary\n",
    "    filtered_dictionary = {}\n",
    "    for each_key in dict_to_filter: #For each key in the dictionary\n",
    "        to_test = np.array(dict_to_filter[each_key])[:,1] #Extract only the timestamps \n",
    "        indexes_to_filter = flatten_f(np.where(np.bitwise_and(to_test>initial_time,to_test<final_time))) #Get indexes of the timestamps that are within the desired time intervals\n",
    "        values_for_key = dict_to_filter[each_key] #Extracts all edges associated with a specific key\n",
    "        \n",
    "        #Redefine values of a particular key\n",
    "        filtered_dictionary.update({each_key: [values_for_key[i] for i in indexes_to_filter]}) #Keeps only those edges that have timestamps within desired time intervals.\n",
    "    return(filtered_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "096260d8-c258-41d1-9e4e-1b0b83b2a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_weights_f(dict_to_standardize):\n",
    "    '''\n",
    "    Function used to summarise all edges with different weights into 1 single edge in a directed graph. It converts a multigraph in a graph. \n",
    "    '''\n",
    "    #Create new dictionary\n",
    "    standard_weighs_dictionary = {}\n",
    "    for each_key in dict_to_standardize:\n",
    "        if len(dict_to_standardize[each_key]) != 0: #If after the filtering the key doesn't have any edges, ignore that key. \n",
    "            #For each key, count how many times each associated vertex appears, and assign that as weight between the key and outgoing vertex\n",
    "            standard_weighs_dictionary.update({each_key: list(collections.Counter(np.array(dict_to_standardize[each_key])[:,0]).items())})\n",
    "    \n",
    "    return(standard_weighs_dictionary) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f51557b-be62-4110-bf1e-d09ffc9585b2",
   "metadata": {},
   "source": [
    "#### Dijkstra Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "30bd328f-a4f2-417d-8eec-fa8145dce986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra_f(graph_to_analyze, start_vertex):\n",
    "    '''\n",
    "    Function used to run Dijkstra algorithm \n",
    "    '''\n",
    "    #****************************************1) Collect all vertexes in the graph**********************************\n",
    "    #Collect all keys (vertexes) in the graph\n",
    "    #Problem: There are other vertexes that are not keys since the graph is directed and also disconnected. We should consider them too. \n",
    "    related_nodes = list()\n",
    "    for each_key in graph_to_analyze.keys():\n",
    "        related_nodes.append([i for i in np.array(graph_to_analyze[each_key])[:,0]])\n",
    "    \n",
    "    #Union of sets: keys of the graph and vertexes that are not keys of the graph but still exist\n",
    "    vertexes = set(graph_to_analyze.keys()).union(set(flatten_f(related_nodes)))\n",
    "    \n",
    "    #*************************************2) Track which vertexes are still unvisited******************************\n",
    "    unvisited_vertexes = vertexes \n",
    "    #***********************************3) Keep track of the smallest distances to each node***********************\n",
    "    #All vertexes are set to have an infinite distance at the beginning. Then they'll be updated\n",
    "    default_distance = float('inf')\n",
    "    smallest_dist_dict = {k: default_distance for k in vertexes}\n",
    "    #Set distance of the starting vertex as zero\n",
    "    smallest_dist_dict[start_vertex] = 0\n",
    "    \n",
    "    #*******4) Keep track of the parent with the smallest distance from which we reach each visited vertex*********\n",
    "    parent_vertex = {k: 'nd' for k in vertexes}\n",
    "    \n",
    "    #Now while we still have vertexes that haven't been visited yet... keep rolling\n",
    "    while(len(unvisited_vertexes)>0):\n",
    "        #Create another dictionary with weights only for the unvisited vertexes\n",
    "        #We use this to select the vertex with the smallest distance and then move to it... 9 to 7 in dict_test_2\n",
    "        dict_unvisited_dist = {each_unvisited_node: smallest_dist_dict[each_unvisited_node] for each_unvisited_node in unvisited_vertexes}\n",
    "        \n",
    "        #We select, from the dictionary of unvisited vertexes, the vertex with the smallest weight\n",
    "        selected_vertex = min(dict_unvisited_dist, key=dict_unvisited_dist.get)\n",
    "        #We remove the selected vertex from unvisited as it is already visited. \n",
    "        unvisited_vertexes.remove(selected_vertex)\n",
    "        \n",
    "        #Now we have to update the distances from the selected vertex to each vertex that is related to it. \n",
    "        if(selected_vertex in graph_to_analyze.keys()): #If there are edges that go out from the selected vertex (aka is a key in graph) update distances of outgoing nodes\n",
    "            for each_related_vertex, dist_related_vertex in graph_to_analyze[selected_vertex]:\n",
    "                #If the distance from the selected vertex plus the dist to the related vertex is smaller than the already reported dist of relat vertex...update!\n",
    "                combined_dist = smallest_dist_dict[selected_vertex] + (1/dist_related_vertex) #Must be 1/dist_related_vertex since a bigger weight means more interactions. Dijkstra only on dist_related_vertex would find the least important relationships.\n",
    "                if(combined_dist < smallest_dist_dict[each_related_vertex]):\n",
    "                    #Update the just discovered shortest distance to the related vertex of the selected vertex\n",
    "                    smallest_dist_dict[each_related_vertex] = combined_dist\n",
    "                    #Keep track of who is the selected vertex that lead to the related_vertex with the shortest dist (aka as the parent)\n",
    "                    parent_vertex[each_related_vertex] = selected_vertex\n",
    "            #print(len(unvisited_vertexes))\n",
    "    \n",
    "    return smallest_dist_dict, parent_vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3555c-0cc0-4e12-aefc-d98cdde321e8",
   "metadata": {},
   "source": [
    "#### Function to rebuild the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "38ac3548-15b6-4623-8e78-c12ddae501e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_path_f(graph_to_analyze_inp,starting_vertex_inp,ending_vertex_inp):\n",
    "    '''\n",
    "    Runs Dijkstra from the starting vertex. Gets dict of min distance from starting_vertex to each vertex that can be reached from it\n",
    "    and gets dict of the parent vertex that lead to each vertex that can be reached from starting vertex. Then reconstructs the path.\n",
    "    '''\n",
    "    min_dist_dict, parent_dict = dijkstra_f(graph_to_analyze_inp,starting_vertex_inp) \n",
    "    \n",
    "    #List to reconstruct the path that lead to each vertex\n",
    "    path_to_goal = list()\n",
    "    #path_to_goal.append(ending_vertex)\n",
    "    #Define the goal vertex from which we will start constructing the path that lead to it from the starting_vertex\n",
    "    goal = starting_vertex_inp\n",
    "    \n",
    "    #While we haven't reached our goal vertex, keep rolling...unless it's impossible to construct a path between starting and ending vertex\n",
    "    #stopping_clause = False\n",
    "    while ending_vertex_inp != goal:\n",
    "        #If there's no parent vertex... it was not possible to reach ending_vertex from starting_vertex, so stop searching\n",
    "        if (ending_vertex_inp not in parent_dict.keys()) or (parent_dict[ending_vertex_inp] == 'nd'):\n",
    "            path_to_goal.clear()\n",
    "            return(print(\"Impossible to reach vertex\",ending_vertex_inp,\"from vertex\",goal,\"!\"))\n",
    "            #stopping_clause = True\n",
    "            break #Stop searching\n",
    "        else:\n",
    "            #print(parent_dict[ending_vertex]) #Debug\n",
    "            #Add the parent of the list to reconstruct the path that lead from starting_vertex to ending_vertex\n",
    "            path_to_goal.append(parent_dict[ending_vertex_inp])\n",
    "            #Redefine parent vertex for next iteration and continue searching backwards\n",
    "            ending_vertex_inp = parent_dict[ending_vertex_inp]\n",
    "    return(path_to_goal[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "823a4a7f-8c74-4ace-9705-da7bd2859179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality_3(graph_to_analyze_inp, interval_time, p1, pn, p): #Where interval of time has to have a default\n",
    "    '''\n",
    "    Function that takes a graph, an interval of time and 1) A starting vertex 2) An ending (or goal) vertex 3) And a list of vertexes.\n",
    "    The goal is to find the shortest route between the starting vertex and the ending vertex, that passes through the list of vertexes in order.\n",
    "    For this the function breaks the list in couples of subsequent vertexes and finds the shortest route between them\n",
    "    Collects the shortest paths in a list and finds, at the end, the shortest route between starting and ending vertex. \n",
    "    '''\n",
    "    #First filter the graph by time interval\n",
    "    converted_interval=convert_interval(interval_time) #Transforming inputs of date intervals into integers\n",
    "    #Filter the graph by the timestamps (converted to integers) given by the user\n",
    "    filtered_dict = filter_by_timestamps_f(converted_interval[0],converted_interval[1],graph_to_analyze_inp)\n",
    "    #Second standardize the filtered graph to sum up the weights of all the edges with the same direction between each pair of vertexes\n",
    "    graph_to_analyze = standardize_weights_f(filtered_dict)\n",
    "\n",
    "    if isinstance(p, list):\n",
    "        p.insert(0,p1) #Set the parameter p1 as the first element of the list p.\n",
    "        p.insert(len(p),pn) #Set the parameter pn as the last element of the list p. \n",
    "        \n",
    "        shortest_route = list() #Define a list to collect the shortest route between a couple of vertexes\n",
    "        \n",
    "        for i in range(0,len(p)-1): #Goes through the list given by the user taking couples of vertexes\n",
    "            \n",
    "            starting_vertex = p[i] #Take the first vertex of the couple\n",
    "            ending_vertex = p[i+1] #Take the second vertex of the couple\n",
    "            \n",
    "            #Explore the shortest path between starting and ending vertex\n",
    "            path = reconstruct_path_f(graph_to_analyze,starting_vertex,ending_vertex) \n",
    "            #Check if the returned type is None\n",
    "            if path is None:\n",
    "                break\n",
    "            #Save the path found between the 2 vertexes\n",
    "            shortest_route.extend(path) \n",
    "            \n",
    "            #If is the last iteration, and all the paths have been found, just append the goal vertex to the list.\n",
    "            if i == (len(p)-2): \n",
    "                shortest_route.append(pn) #This can be removed. \n",
    "    else:\n",
    "        print(\"Input p is not a list. Please insert a object of type list.\")\n",
    "    \n",
    "    return shortest_route, graph_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900cafe-31ca-486d-afcc-0772843b3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_f3(graph_to_visualize, path_to_visualize):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for each_key in graph_to_visualize.keys():\n",
    "        for each_vertex in graph_to_visualize[each_key]:\n",
    "            G.add_edge(each_key,each_vertex[0])\n",
    "    \n",
    "    res = path_to_visualize\n",
    "    \n",
    "    k = G.subgraph(res)\n",
    "    starting_node = G.subgraph(path_f3[0])\n",
    "    ending_node = G.subgraph(path_f3[-1])\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    pos = nx.spring_layout(G,k = 1, iterations=50, seed=7)\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(G, pos, alpha=0.3, node_size=10)\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.2, width=0.2)\n",
    "    \n",
    "    nx.draw_networkx(k, pos=pos,with_labels=True, node_color = 'r', node_size = 30)\n",
    "    nx.draw_networkx(starting_node, pos=pos,with_labels=True, node_color = 'y', node_size = 100)\n",
    "    nx.draw_networkx(ending_node, pos=pos,with_labels=True, node_color = 'y', node_size = 100)\n",
    "    nx.draw_networkx_edges(k, pos, width=1, edge_color = 'm')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "96b9db19-46ee-4b63-82d2-288d45ea91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_f3, total_graph = functionality_3(my_dict,[(4,1,2011),(6,1,2011)],267,589854,[476,1053,1968])\n",
    "path_f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa11155c-4c8e-447f-b921-0e703f584e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[267,\n",
       " 48465,\n",
       " 8992,\n",
       " 289466,\n",
       " 84325,\n",
       " 68105,\n",
       " 155077,\n",
       " 296568,\n",
       " 419970,\n",
       " 449907,\n",
       " 476,\n",
       " 386579,\n",
       " 187606,\n",
       " 524436,\n",
       " 481061,\n",
       " 456,\n",
       " 585737,\n",
       " 415784,\n",
       " 317283,\n",
       " 165520,\n",
       " 505259,\n",
       " 1053,\n",
       " 501518,\n",
       " 501146,\n",
       " 556363,\n",
       " 14955,\n",
       " 212443,\n",
       " 429982,\n",
       " 511601,\n",
       " 13005,\n",
       " 1968,\n",
       " 19563,\n",
       " 252047,\n",
       " 511601,\n",
       " 429982,\n",
       " 573261,\n",
       " 589854]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d0e0e-c24a-46c2-8dd9-66804c8ffc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_f3(total_graph,path_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c2b93",
   "metadata": {},
   "source": [
    "## Functionality 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a5be3",
   "metadata": {},
   "source": [
    "You can find the functionality4 at the end of this part but our choice was splitting the Process\n",
    "into 4 steps to be more readable \n",
    "\n",
    "You can find a detailed description of every function in support_function4.py\n",
    "\n",
    "Pipeline:\n",
    "1. converting interval of time\n",
    "2. filtering dictionary using interval of time\n",
    "3. KARGER ALGORITHM \n",
    "4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ec1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing the data adn libraries\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "\n",
    "with open('data/interactions.pickle', 'rb') as handle:\n",
    "    my_dict = pickle.load(handle)\n",
    "\n",
    "#(user2,time_stamp,score_associated_to_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf952b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from support_functions4 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486f89b",
   "metadata": {},
   "source": [
    "### Part 1: converting time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e1a6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14116, 14117]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imagine to take in input date in format [(dd,mm,yyyy),(dd,mm,yyyy)]\n",
    "\n",
    "#first day included, second day escluded\n",
    "interval=[(29,7,2008),(30,7,2008)] \n",
    "\n",
    "converted_interval=convert_interval(interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fdd30",
   "metadata": {},
   "source": [
    "### Part 2: filtering dictionary using the interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6fd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dictionary=filter_dictionary(my_dict,converted_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bb3a2",
   "metadata": {},
   "source": [
    "Create the final dictionary eliminating the edges that start from a node a go to the same node and take the sum if there are two edges that start from the same node and point the same node.\n",
    "This dictionary does not have timestamp anymore since we do not require it anymore\n",
    "\n",
    "**Example** : \n",
    "* if i have {1:[(1,10)]} I drop this element since user1 gives an answer to himself\n",
    "* if i have {1:[(2,10),(2,5)]} i take {'1,2':sum(10+5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf84dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=final_transformation(filtered_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcfab5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(G))==0:\n",
    "    print('in this interval we do not have users')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75eb97c",
   "metadata": {},
   "source": [
    "### Part 3: Karger Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55720dd8",
   "metadata": {},
   "source": [
    " For the supernode I will use the format 'nodex|nodey|nodez' \n",
    "\n",
    "  We can execute the algorith in a real situation: every check was positive so i expect a result, at least a non admissible one\n",
    " * NOTE : we run Karger not the appropriate number of times because of running time but, if you want, you can change this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "005ba315",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We run Karger just \n",
    "min_cut,partitionA,partitionB=Karger(G,'17','51')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c824dfa",
   "metadata": {},
   "source": [
    "## FUNCTIONALITY 4 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "652cb924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality4(my_dict,interval,s,t):\n",
    "    converted_interval=convert_interval(interval)\n",
    "    filtered_dictionary=filter_dictionary(my_dict,converted_interval)\n",
    "    G=final_transformation(filtered_dictionary)\n",
    "\n",
    "    if(len(G))==0:\n",
    "        return('in this interval we do not have users')\n",
    "\n",
    "    min_cut,partitionA,partitionB=Karger(G,s,t)\n",
    "    print(min_cut)\n",
    "\n",
    "    return(min_cut,partitionA,partitionB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027d927",
   "metadata": {},
   "source": [
    "It will take some min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56300666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "min_cut,partitionA,partitionB=functionality4(my_dict,[(29,7,2008),(30,7,2008)],'17','51')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2cde8",
   "metadata": {},
   "source": [
    "## VISUALIZATION 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6585c",
   "metadata": {},
   "source": [
    "We can decide between many different visualization but I think the most rappresentative one is the last cut between the two partitions of the graph.\n",
    "In addition, is very difficult to represent a large number of links in a single image and this goes in opposite direction with respect to the idea of helping understand the process with an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42dc1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "\n",
    "G.add_edge('partitionA','partitionB',weight=min_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfafd7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nx.draw(G, with_labels=True)\n",
    "pos=nx.spring_layout(G)\n",
    "labels = nx.get_edge_attributes(G,'weight')\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c70ece-57ae-49c8-9748-5262d68f02de",
   "metadata": {},
   "source": [
    "# Algorithmic Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a243497-5d2f-4e83-8391-ad08e4211ee8",
   "metadata": {},
   "source": [
    "**A number n of kids are in a camp. Between some k pairs of them (a kid can be part of more than one pairs) there are often fights. At night there are two dormitories where the kids can sleep. We want, if possible, to assign each kid in one of the two dormitories in such a way that each pair of kids that fights often is assigned to a different dormitory. (There are no space problems and the two dormitories can have different number of kids.)**\n",
    "\n",
    "**Give an algorithm that is linear in n and k that is able to answer whether such an assignment is possible and, if so, return one.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1352ea-84a8-431a-84e8-cbef8df6986d",
   "metadata": {},
   "source": [
    "We decided to start with an implementation that require a dictionary in which the keys are the kids and their values is a set:\n",
    "\n",
    "To compute the function we see if the set of a kid is in a dormitory (they are also sets) with usually (I mean on average: see https://wiki.python.org/moin/TimeComplexity, set section, intersection s&t) O(min(len(set),len(dormitoru))) which are usually small numbers.\n",
    "\n",
    "We iterate iver the dictionary once and we make all this operation, but if we find an incoherence, we stop the iteration and return impossible disposition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7839635d-7415-446f-982d-3272159ef8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary and sets\n",
    "######## EXAMPLE 1 ########\n",
    "kids={}\n",
    "#initialize\n",
    "kids[0]=set([1,2])\n",
    "kids[1]=set([0,2])\n",
    "kids[2]=set([0,1])\n",
    "kids[3]=set([])\n",
    "\n",
    "###### EXAMPLE 2 #######\n",
    "adj_list3 = {\n",
    "\"A\" : set([\"B\", \"C\"]),\n",
    "\"B\" : set([\"A\", \"D\"]),\n",
    "\"C\" : set([\"A\", \"E\"]),\n",
    "\"D\" : set([\"G\"]),\n",
    "\"E\" : set([\"C\", \"F\"]),\n",
    "\"F\" : set([\"E\"]),\n",
    "\"G\" : set([\"D\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8423f102-10f5-479d-8ebf-2e2e900d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(kids):\n",
    "    dormitory1=set()\n",
    "    dormitory2=set()\n",
    "\n",
    "    for k,v in kids.items():\n",
    "\n",
    "        if (v.isdisjoint(dormitory1)):\n",
    "            dormitory1.add(k)\n",
    "        elif ( (not(v.isdisjoint(dormitory1))) & (v.isdisjoint(dormitory2)) ):\n",
    "            dormitory2.add(k)\n",
    "        elif  ( (not(v.isdisjoint(dormitory1))) & (not(v.isdisjoint(dormitory2))) ):\n",
    "            return('Impossible disposition')\n",
    "        \n",
    "    print('dormitory1:',dormitory1)\n",
    "    print('dormitory2:',dormitory2)\n",
    "    return('We achieved our goal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c1999-2d63-4dab-b92b-8cb6e6d18545",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution(adj_list3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
