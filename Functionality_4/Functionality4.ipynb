{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Hypothesis* in which we are working are the following: undirect graph retrived filtering the intervals of times that has as weight the sum of all the weight of the edges between the two original nodes. \n",
    "\n",
    "* *Costraint*:  create two partitions A and B of nodes such that user1 belongs to A and user2 belongs to B \n",
    "\n",
    "* *Goal*: minimizing the weight of the cut "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINE:\n",
    "\n",
    "1. converting the interval of time\n",
    "2. filtering dictionary using the interval of time\n",
    "3. aggregate the edges between two nodes summing their weights\n",
    "* aggregate by user2 for every first user\n",
    "* create a dictionary with keys= (user1,user2) and weight the sum of the weights between them\n",
    "4. defining Stoer Wagner algorithm for two users\n",
    "* define supernode\n",
    "* define step\n",
    "* define iteration\n",
    "* use all these functions to create Stoer Wagner\n",
    "5. apply the algorithm to the dictionary to retrieve the number of cuts ans their total weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/interactions.pickle', 'rb') as handle:\n",
    "    my_dict = pickle.load(handle)\n",
    "\n",
    "#(user2,time_stamp,score_associated_to_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1: converting the interval of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_date_to_int(date):\n",
    "    '''\n",
    "    INPUT: (day,month,year)\n",
    "    OUTPUT: correspondent integer\n",
    "    '''\n",
    "    if date[1]==2:\n",
    "        integer=date[0]+date[1]*28+(date[2]-1970)*365\n",
    "    if date[1] in [4,6,9,11]:\n",
    "        integer=date[0]+date[1]*30+(date[2]-1970)*365\n",
    "    else:\n",
    "        integer=date[0]+date[1]*31+(date[2]-1970)*365\n",
    "    return(integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_interval(interval):\n",
    "    '''\n",
    "    INPUT= interval of time in format [(dd,mm,yyyy),(dd,mm,yyyy),(dd,mm,yyyy),(dd,mm,yyyy)] --> [start1,end1,start2,end2]\n",
    "    OUTPUT: interval of time in format [encoded_start1,encoded_end1,encoded_start2,encoded_end2] where encoded are integers values\n",
    "    '''\n",
    "    new_int=[]\n",
    "    for date in interval:\n",
    "        new_int.append(from_date_to_int(date))\n",
    "    \n",
    "    return( new_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to try\n",
    "#from_date_to_int((22,5,1973))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14116, 14117]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imagine to take in input date in format [(dd,mm,yyyy),(dd,mm,yyyy)]\n",
    "\n",
    "#first day included, second day escluded\n",
    "interval=[(29,7,2008),(30,7,2008)] \n",
    "\n",
    "converted_interval=convert_interval(interval)\n",
    "converted_interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: filtering dictionary using the interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova={}\n",
    "prova[1]=[(2,736383,10),(3,43,5)]\n",
    "prova[2]=[(3,729305,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dictionary(dictionary,converted_interval): \n",
    "    filtered_dictionary={}\n",
    "    for key,value in dictionary.items():\n",
    "        for elem in value:\n",
    "            if ( (elem[1]>=converted_interval[0] and elem[1]<converted_interval[1]) ): # or (elem[1]>converted_interval[2] and elem[1]<converted_interval[3]) ):\n",
    "                try:\n",
    "                    filtered_dictionary[key].append(elem)\n",
    "                except:\n",
    "                    filtered_dictionary[key]=[elem]\n",
    "    return(filtered_dictionary)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dictionary=filter_dictionary(my_dict,converted_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(filtered_dictionary)==0):\n",
    "    print('no elements in this interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: aggregate the edges between two nodes summing their weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "firstly let's reduce the value of every user by summing they score if the other user is the same:\n",
    "1:[(2,3343,10),(2,2434,5),(78,433,5)] becames 1:{2:15, 78:5}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova={}\n",
    "prova[1]=[(2,1111,10),(2,11111,5)]\n",
    "prova[2]=[(1,1111,5),(2,34343,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I group for every user all the relations that he had with another user--> rough way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we need to costruct  just one edge between the two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate={}\n",
    "for key,value in filtered_dictionary.items():\n",
    "    dizio={}\n",
    "    for elem in value:\n",
    "        #check user2 in keys: if it is NOT in the dictionary\n",
    "        try:\n",
    "            previous=dizio[elem[0]]\n",
    "            dizio[elem[0]]=previous+elem[2]\n",
    "        except:\n",
    "            dizio[ elem[0] ]=elem[2]\n",
    "    \n",
    "    intermediate[key]=dizio\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge all the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prova={}\n",
    "prova[1]={2:10,3:5}\n",
    "prova[2]={1:5,3:10}\n",
    "prova[3]={2:5,1:10,8:2}\n",
    "type(prova[1])\n",
    "len(prova)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict={}\n",
    "for key,value in intermediate.items():\n",
    "\n",
    "    for key1,value1 in value.items():\n",
    "    \n",
    "        if ((str(key)+','+str(key1)) in final_dict):\n",
    "            previous=final_dict[str(key)+','+str(key1)]\n",
    "            final_dict[str(key)+','+str(key1)] =previous+value1\n",
    "\n",
    "        if ((str(key1)+','+str(key)) in final_dict):\n",
    "            previous=final_dict[str(key1)+','+str(key)]\n",
    "            final_dict[str(key1)+','+str(key)]=previous+value1\n",
    "\n",
    "        else:\n",
    "            final_dict[str(key)+','+str(key1)]=value1\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_dict is a dictionary in which we have all the edges of our indirect graph in the format 'user1,user2' : value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find MIN CUT in undirect graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need a function to merge two nodes and that give the new graph encoded as dictionary as output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supernode(G, node1 ,node2):\n",
    "       '''\n",
    "       INPUT: G=graph represented as dictionary\n",
    "              node1\n",
    "              node2\n",
    "       OUTPUT: new graph in which node1 and node2 have been merged together in which the new edge will have the notation ['node1|node2,user']=value\n",
    "              new_edges\n",
    "       '''\n",
    "       \n",
    "       #find edges to remove\n",
    "       old_edges=[]\n",
    "       for k,v in G.items():\n",
    "\n",
    "              if ( (k.split(',')[-1])==node1 or (k.split(',')[-2])==node1 ):\n",
    "                     old_edges.append(k)\n",
    "                     \n",
    "              if ( (k.split(',')[-1])==node2 or (k.split(',')[-2])==node2 ):\n",
    "                     old_edges.append(k)\n",
    "\n",
    "       #remove doubles from old_edges \n",
    "       old_edges=list(set(old_edges))\n",
    "       \n",
    "\n",
    "       #new_graph\n",
    "       new_dict=G.copy()\n",
    "       for key in old_edges:\n",
    "              del new_dict[key]\n",
    "\n",
    "       #remove edge between node1 and node2\n",
    "       for old_edge in old_edges:\n",
    "              if (old_edge.split(',')[-1]==node1 and old_edge.split(',')[-2]==node2):\n",
    "                     old_edges.remove(old_edge)\n",
    "              if (old_edge.split(',')[-2]==node1 and old_edge.split(',')[-1]==node2):\n",
    "                     old_edges.remove(old_edge)      \n",
    "       \n",
    "       \n",
    "       #now i need to find all the edges that go to the same nodes and sum them to produce a new edge that will have the following shape {node1,node2,user: sum edges from node1 to user + sum edges node2 a user)}\n",
    "       new_edges={}\n",
    "       for edge in old_edges:\n",
    "              \n",
    "\n",
    "              if (edge.split(',')[-1]==str(node1) or edge.split(',')[-1]==str(node2)):\n",
    "                     \n",
    "                     try:\n",
    "                            previous=new_edges[str(node1)+'|'+str(node2)+','+edge.split(',')[-2]]\n",
    "                            new_edges[str(node1)+'|'+str(node2)+','+edge.split(',')[-2]]=previous+G[edge]\n",
    "                     except:\n",
    "                            new_edges[str(node1)+'|'+str(node2)+','+edge.split(',')[-2]]=G[edge]\n",
    "                            \n",
    "              if (edge.split(',')[-2]==str(node1) or edge.split(',')[-2]==str(node2)):\n",
    "                     \n",
    "                     try:\n",
    "                            previous=new_edges[str(node1)+'|'+str(node2)+','+edge.split(',')[-1]]\n",
    "                            new_edges[str(node1)+'|'+str(node2)+','+edge.split(',')[-1]]=previous+G[edge]\n",
    "                     except:\n",
    "                            new_edges[str(node1)+'|'+str(node2)+','+edge.split(',')[-1]]=G[edge]\n",
    "\n",
    "       \n",
    "       for k,v in new_edges.items():\n",
    "              new_dict[k]=v\n",
    "       \n",
    "\n",
    "       return new_dict,new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nuovo_diz,new=supernode(prova,'4','5')\n",
    "nuovo_diz\n",
    "nuovo_diz,new=supernode(nuovo_diz,'4|5','3')\n",
    "nuovo_diz\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now I need to define a function that compute the elementary step given a starting point: i retrieve the edge with the max weight between the edges attached to the starting point and then i create a supernode between the starting point and the node connect to this edge that I have found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I need to define the simple step to reduce every subgrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(G,s,t):\n",
    "    '''\n",
    "    INPUT: graph G, node s (source node), node t (sink node) [  format 's' and 't']\n",
    "    OUTPUT: new graph given merging sorce node with the most tightly connected vertex\n",
    "    '''\n",
    "    \n",
    "    #search the edges connected to s\n",
    "    \n",
    "    other_user=[]\n",
    "    value=0\n",
    "    for k,v in G.items():\n",
    "        \n",
    "        if(k.split(',')[-2]==s):\n",
    "            #not the sink\n",
    "            if(k.split(',')[-1]!=t):\n",
    "                if v>value:\n",
    "                    value=v\n",
    "                    other_user.append(k.split(',')[-1])\n",
    "\n",
    "        if (k.split(',')[-1]==s):\n",
    "            if(k.split(',')[-2]!=t):\n",
    "                if v>value:\n",
    "                    value=v\n",
    "                    other_user.append(k.split(',')[-2])\n",
    "\n",
    "    \n",
    "    # I found the edge that has the biggest weight \n",
    "    subgraph,new_edges = supernode(G,s,other_user[-1])\n",
    "\n",
    "    return subgraph,new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "prova={}\n",
    "prova['1,2']=5\n",
    "prova['1,4']=2\n",
    "prova['2,4']=1\n",
    "prova['2,3']=6\n",
    "prova['3,4']=1\n",
    "prova['3,5']=3\n",
    "prova['4,5']=2\n",
    "\n",
    "ris1,inutile=step(prova,'1','5')\n",
    "ris2,inutile=step(ris1,'1|2','5')\n",
    "ris3,inutile=step(ris2,'1|2|3','5')\n",
    "ris3\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i can implement an ITERATION of Stoer Wagner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(G,s,t):\n",
    "    '''\n",
    "    INPUT: grapg G, source node s and sink node t\n",
    "    OUTPUT: the values of the cut and the last two elements of the graph that will be merged before the next iteration\n",
    "    '''\n",
    "    #initialization\n",
    "    iteration_dict,new_edge= step(G,s,t)\n",
    "   \n",
    "    while ( len(iteration_dict)>2  and list(new_edge)[0].split(',')[1]!=t) :\n",
    "        \n",
    "        start=list(new_edge)[0].split(',')[0]\n",
    "        iteration_dict,new_edge= step(iteration_dict,start,t)\n",
    "\n",
    "    cut=list(iteration_dict.values())[0]\n",
    "    #node to merge:\n",
    "    node1_to_merge=list(iteration_dict.keys())[0].split(',')[0].split('|')[-1]\n",
    "    node2_to_merge=list(iteration_dict.keys())[0].split(',')[-1]\n",
    "    return cut,node1_to_merge,node2_to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faccio una prova\n",
    "'''\n",
    "cuts=[]\n",
    "s='1'\n",
    "t='5'\n",
    "iteration_graph=prova.copy()\n",
    "cut,node1_to_merge,node2_to_merge=iteration(iteration_graph,s,t)\n",
    "cuts.append(cut)\n",
    "\n",
    "#finito la prima iterazione\n",
    "# creo il nuovo grafo e parto da li\n",
    "prova,new_e=supernode(prova,node1_to_merge,node2_to_merge)\n",
    "iteration_graph=prova.copy()\n",
    "t=node1_to_merge+'|'+node2_to_merge\n",
    "cut,node1_to_merge,node2_to_merge=iteration(iteration_graph,s,t)\n",
    "\n",
    "#finita altra iterazione che va bene\n",
    "#credo nuovo grafo e riparto da li\n",
    "prova,new_e=supernode(prova,node1_to_merge,node2_to_merge)\n",
    "iteration_graph=prova.copy()\n",
    "t=node1_to_merge+'|'+node2_to_merge\n",
    "cut,node1_to_merge,node2_to_merge=iteration(iteration_graph,s,t)\n",
    "\n",
    "# anche questa iterazione è andata bene: devo fare l'ultima\n",
    "prova,new_e=supernode(prova,node1_to_merge,node2_to_merge)\n",
    "\n",
    "# anche questa iterazione è andata bene: devo fare l'ultima\n",
    "prova,new_e=supernode(prova,node1_to_merge,node2_to_merge)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stoer_Wagner(G,s,t):\n",
    "\n",
    "    cuts=[]\n",
    "    #initialize\n",
    "    iteration_graph=G.copy()\n",
    "    cut,node1_to_merge,node2_to_merge=iteration(iteration_graph,s,t)\n",
    "    cuts.append(cut)\n",
    "    #smaller_graph\n",
    "    G,new_e=supernode(G,node1_to_merge,node2_to_merge)\n",
    "    t=node1_to_merge+'|'+node2_to_merge\n",
    "\n",
    "    while len(G)>2:\n",
    "\n",
    "        iteration_graph=G.copy()\n",
    "        t=node1_to_merge+'|'+node2_to_merge\n",
    "        cut,node1_to_merge,node2_to_merge=iteration(iteration_graph,s,t)\n",
    "        cuts.append(cut)\n",
    "        G,new_e=supernode(G,node1_to_merge,node2_to_merge)\n",
    "\n",
    "    if len(G)==1:\n",
    "        cuts.append(list(G.values())[0])\n",
    "\n",
    "    return(min(cuts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova={}\n",
    "prova['1,2']=3\n",
    "prova['1,4']=4\n",
    "prova['2,4']=1\n",
    "prova['2,3']=6\n",
    "prova['3,4']=1\n",
    "prova['3,5']=2\n",
    "prova['4,5']=3\n",
    "prova['5,6']=2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizionario=prova\n",
    "#dizionario=final_dict\n",
    "taglio=Stoer_Wagner(dizionario,'1','7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taglio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0e40e7c7a66e87c69eaa7498d7778a1d8fa6b3e422091d0b3e8dafd8f730247"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('fds': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
